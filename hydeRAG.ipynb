{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. hydeRAG\n",
    "\n",
    "<img src=\"https://humanloop.com/blog/rag-architectures/HyDe.png\" height=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the LLM and the Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GROQ and OpenAI API keys\n",
    "groq_api_key = \"\"\n",
    "google_api_key = \"\"\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "Embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and formating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea-level rise, more frequent and severe heatwaves, droughts, and floods, melting of polar ice caps, intense storms, and changes in precipitation patterns.\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "loader = PyPDFDirectoryLoader(\"./pdf\")  # Load PDFs from directory\n",
    "docs = loader.load()\n",
    "\n",
    "# Splitting / Creating Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Creating Embeddings by Passing HyDe Embeddings to Vector Store\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=Embeddings)\n",
    "\n",
    "# Creating Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "# Importing the Prompt Template\n",
    "template = \"\"\"For the given question try to generate a hypothetical answer\n",
    "Only generate the answer and nothing else:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "# for converting the query to a prompt\n",
    "Prompt = ChatPromptTemplate.from_template(template)\n",
    "query = Prompt.format(question='What are some climate related risks?')\n",
    "\n",
    "hypothetical_answer = llm.invoke(query).content\n",
    "print(hypothetical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_30900\\1237761195.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  similar_docs = retriever.get_relevant_documents(hypothetical_answer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature means, desertification, decreasing precipitation, loss of biodiversity, land and forest degradation, glacial retreat and related impacts, ocean \n",
      "acidification, sea level rise and salinization. {2.1.2}\n",
      "\n",
      "Very likely\n",
      "Global sea\n",
      "level rise\n",
      "Glacier\n",
      "retreat\n",
      "Medium conﬁdence\n",
      "Increase in \n",
      "compound\n",
      "ﬂooding\n",
      "Increase in \n",
      "agricultural \n",
      "& ecological \n",
      "drought\n",
      "Increase \n",
      "in ﬁre\n",
      "weather\n",
      "\n",
      "conditions, which are increasingly attributed to human inﬂuence\n",
      "Attribution of observed physical climate changes to human inﬂuence:\n",
      "Virtually certain\n",
      "Increase \n",
      "in hot \n",
      "extremes \n",
      "Upper \n",
      "ocean\n",
      "acidiﬁcation\n",
      "pH\n",
      "Likely\n",
      "Increase \n",
      "in heavy \n",
      "precipitation\n",
      "Very likely\n",
      "Global sea\n",
      "level rise\n",
      "Glacier\n",
      "retreat\n",
      "\n",
      "health challenges 36 ( very high confidence), flooding in coastal and other low-lying cities and regions ( high confidence), \n",
      "biodiversity loss in land, freshwater and ocean ecosystems ( medium to  very high confidence, depending on ecosystem),\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieval with hypothetical answer/document\n",
    "similar_docs = retriever.get_relevant_documents(hypothetical_answer)\n",
    "\n",
    "for doc in similar_docs:\n",
    " print(doc.page_content)\n",
    " print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Answer the following question based on this context:\n",
      "\n",
      "temperature means, desertification, decreasing precipitation, loss of biodiversity, land and forest degradation, glacial retreat and related impacts, ocean \n",
      "acidification, sea level rise and salinization. {2.1.2}\n",
      "\n",
      "Very likely\n",
      "Global sea\n",
      "level rise\n",
      "Glacier\n",
      "retreat\n",
      "Medium conﬁdence\n",
      "Increase in \n",
      "compound\n",
      "ﬂooding\n",
      "Increase in \n",
      "agricultural \n",
      "& ecological \n",
      "drought\n",
      "Increase \n",
      "in ﬁre\n",
      "weather\n",
      "\n",
      "conditions, which are increasingly attributed to human inﬂuence\n",
      "Attribution of observed physical climate changes to human inﬂuence:\n",
      "Virtually certain\n",
      "Increase \n",
      "in hot \n",
      "extremes \n",
      "Upper \n",
      "ocean\n",
      "acidiﬁcation\n",
      "pH\n",
      "Likely\n",
      "Increase \n",
      "in heavy \n",
      "precipitation\n",
      "Very likely\n",
      "Global sea\n",
      "level rise\n",
      "Glacier\n",
      "retreat\n",
      "\n",
      "health challenges 36 ( very high confidence), flooding in coastal and other low-lying cities and regions ( high confidence), \n",
      "biodiversity loss in land, freshwater and ocean ecosystems ( medium to  very high confidence, depending on ecosystem),\n",
      "\n",
      "Question: What are some climate related risks?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "Prompt = ChatPromptTemplate.from_template(template)\n",
    "# Creating a function to format the retrieved docs\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "formatted_docs = format_docs(similar_docs)\n",
    "\n",
    "Query_Prompt = Prompt.format(context=formatted_docs, \n",
    "question=\"What are some climate related risks?\")\n",
    "print(Query_Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer :\n",
      "According to the provided context, some climate-related risks include:\n",
      "\n",
      "1. Global sea level rise\n",
      "2. Glacier retreat\n",
      "3. Compound flooding\n",
      "4. Agricultural and ecological drought\n",
      "5. Increase in fire weather conditions\n",
      "6. Hot extremes\n",
      "7. Upper ocean acidification\n",
      "8. Heavy precipitation\n",
      "9. Flooding in coastal and other low-lying cities and regions\n",
      "10. Biodiversity loss in land, freshwater, and ocean ecosystems\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(Query_Prompt)\n",
    "\n",
    "print(\"Final answer :\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on questions which are not clearly present on docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elected officials, government agencies, and specialized organizations that have the authority to make decisions that affect society, economy, and environment, such as presidents, prime ministers, congress members, regulatory bodies, and international organizations.\n"
     ]
    }
   ],
   "source": [
    "question=\"Who are Policymakers?\"\n",
    "\n",
    "# Creating Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "# Importing the Prompt Template\n",
    "template = \"\"\"For the given question try to generate a hypothetical answer\n",
    "Only generate the answer and nothing else:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "# for converting the query to a prompt\n",
    "Prompt = ChatPromptTemplate.from_template(template)\n",
    "query = Prompt.format(question=\"Who are Policymakers?\")\n",
    "\n",
    "hypothetical_answer = llm.invoke(query).content\n",
    "print(hypothetical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Answer the following question based on this context:\n",
      "\n",
      "interests, enable coordination and inform strategy setting but require adequate institutional capacity. Policy support is \n",
      "influenced by actors in civil society, including businesses, youth, women, labour, media, Indigenous Peoples, and local\n",
      "\n",
      "development pathways\n",
      "Civil \n",
      "society\n",
      "Governments\n",
      "Private \n",
      "sector\n",
      "Conditions that enable \n",
      "individual and collective actions\n",
      "• Inclusive governance \n",
      "• Diverse knowledges and values\n",
      "• Finance and innovation\n",
      "• Integration across sectors \n",
      "and time scales\n",
      "• Ecosystem stewardship\n",
      "\n",
      "communities. Effectiveness is enhanced by political commitment and partnerships between different groups in society. \n",
      "(high confidence) {2.2, 4.7}\n",
      "C.6.3 Effective multilevel governence for mitigation, adaptation, risk management, and climate resilient development is\n",
      "\n",
      "the part of the Intergovernmental Panel on Climate Change concerning the legal status of any country, territory, city or area or of \n",
      "its authorities, or concerning the delimitation of its frontiers or boundaries. The mention of specific companies or products does\n",
      "\n",
      "Question: Who are Policymakers?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar_docs = retriever.get_relevant_documents(hypothetical_answer)\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "Prompt = ChatPromptTemplate.from_template(template)\n",
    "# Creating a function to format the retrieved docs\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "formatted_docs = format_docs(similar_docs)\n",
    "\n",
    "Query_Prompt = Prompt.format(context=formatted_docs, \n",
    "question=\"Who are Policymakers?\")\n",
    "print(Query_Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer :\n",
      "Based on the provided context, Policymakers are not explicitly mentioned. However, it can be inferred that Policymakers are likely to be Governments, which are mentioned as one of the actors influencing policy support, along with actors in civil society, including businesses, youth, women, labour, media, Indigenous Peoples, and local communities.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(Query_Prompt)\n",
    "\n",
    "print(\"Final answer :\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
